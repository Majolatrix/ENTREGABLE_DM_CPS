}
install.packages(c("tidyverse","tidytext","tm","proustr"))
install.packages(c("tidyverse", "tidytext", "tm", "proustr"))
knitr::opts_chunk$set(echo = TRUE)
arte_hashtag <- read_csv('arte_hashtag.csv')
arte_hashtag <- read_csv('arte_hashtag.csv')
library(tidyverse)
library(tidytext)
library(tm)
library(proustr)
knitr::opts_chunk$set(echo = TRUE)
arte_hashtag <- read_csv('arte_hashtag.csv')
arte_word <- read_csv('arte_word.csv')
DATA_ART = rbind (arte_hashtag, arte_word)
View(DATA_ART)
DATA_ART <- DATA_ART %>% select ("created_at" ,
"screen_name" ,
"text",
"source",
"is_retweet",
"hashtags",
"symbols",
"lang",
"retweet_text"   ,
"retweet_created_at" ,
"retweet_source") %>%
filter(lang == "es")
summary(DATA_ART)
Tokenización y depuración de la base con stopwords y variable de palabras que no importan
View(DATA_ART)
silly_words <- c('rt','t.co','https','tan','like','follow','youtube','instagram','facebook','y)
silly_words <- c('rt','t.co','https','tan','like','follow','youtube','instagram','facebook','y')
silly_words <- c('rt','t.co','https','tan','like','follow','youtube','instagram','facebook','y'
silly_words <- c('rt','t.co','https','tan','like','follow','youtube','instagram','facebook','y')
silly_words <- c('rt','t.co','https','tan','like','follow','youtube','instagram','facebook','y')
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^@"))
DATA_ART %>%
unnest_tokens(Palabra, text) %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^@"))
silly_words <- c('rt','t.co','https','tan','like','follow','youtube','instagram','facebook','y','así','bts_twt',
'q','the','theframe','theframesamsung','d','va','cada','mas','as','lpm','da','etc','j','aqui',
'in','s','v','vez','to','fe0f')
DATA_ART %>%
unnest_tokens(Palabra, text) %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^@"))
silly_words <- c('rt','t.co','https','tan','like','follow','youtube','instagram','facebook','y','así','bts_twt',
'q','the','theframe','theframesamsung','d','va','cada','mas','as','lpm','da','etc','j','aqui',
'in','s','v','vez','to','fe0f','u')
DATA_ART %>%
unnest_tokens(Palabra, text) %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^@"))
View(DATA_ART)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^@"))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets', to_lower = TRUE) %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^@"))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^@"))
arrange(desc(n))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^@"))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets', to_lower = TRUE) %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^@"))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets', to_lower= TRUE) %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^@"))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets', to_lower= FALSE) %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^@"))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^@"))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^#|^@")) %>%
arrange(desc(n))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^#|^@")) %>%
arrange(desc(n))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
arrange(desc(n))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
arrange(desc(5))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
arrange(desc(n), n == 5)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
cantidad (count(Palabra, sort = TRUE)) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
arrange(desc(n))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
cantidad (count(Palabra, sort = TRUE)) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
arrange(desc(n)) %>%
head(DATA_ART,5)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
cantidad (filter(!Palabra%in%stopwords('es') %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
arrange(desc(n)) %>%
head(DATA_ART,5)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
arrange(desc(n)) %>%
head(DATA_ART,5)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
#arrange(desc(n)) %>%
head(DATA_ART,5)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
#arrange(desc(n)) %>%
slice(1:4)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte")) %>%
arrange(desc(n)) %>%
slice(1:4)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte")) %>%
arrange(desc(n)) %>%
slice(1:5)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte")) %>%
arrange(asc(n)) %>%
slice(1:5)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte")) %>%
arrange(desc(n)) %>%
slice(1:5)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte|^#art")) %>%
arrange(desc(n)) %>%
slice(1:5)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte|^#art")) %>%
arrange(desc(n))
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte|^#art")) %>%
arrange(desc(n)) %>%
slice(1:5)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte|^#art"))
DATA_ART %>%
filter(isRetweet==FALSE)
DATA_ART %>%
filter(isRetweet==FALSE) %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte|^#art")) %>%
arrange(desc(n)) %>%
slice(1:5)
DATA_ART %>%
filter(is_retweet==FALSE) %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte|^#art")) %>%
arrange(desc(n)) %>%
slice(1:5)
DATA_ART %>%
filter(is_retweet==FALSE) %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte|^#art|^#theframe|^#theframesamsung")) %>%
arrange(desc(n)) %>%
slice(1:5)
DATA_ART %>%
filter(is_retweet==FALSE) %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte|^#art|^#theframe|^#theframesamsung|^#samsung")) %>%
arrange(desc(n)) %>%
slice(1:5)
DATA_ART %>%
filter(is_retweet==FALSE) %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte|^#art|^#theframe|^#theframesamsung|^#samsung")) %>%
arrange((n)) %>%
slice(1:5)
DATA_ART %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#arte|^#art")) %>%
arrange((n)) %>%
slice(1:5)
DATA_ART %>%
filter(is_retweet==FALSE) %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^#")) %>%
filter(!str_detect(Palabra,"^#|^@")) %>%
arrange(desc(n)) %>%
slice(1:5)
DATA_ART %>%
filter(is_retweet==FALSE) %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]")) %>%
filter(!str_detect(Palabra,"^#|^@")) %>%
arrange(desc(n)) %>%
slice(1:5)
DATA_ART %>%
filter(is_retweet==FALSE) %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]")) %>%
filter(!str_detect(Palabra,"^#|^@|^arte")) %>%
arrange(desc(n)) %>%
slice(1:5)
DATA_ART %>%
filter(is_retweet==FALSE) %>%
unnest_tokens(Palabra, text, token='tweets') %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]")) %>%
filter(!str_detect(Palabra,"^#|^@|^arte")) %>%
arrange(desc(n)) %>%
slice(1:5)
unnest_tokens(Palabra, text, token='ngrams', n = 2)
DATA_ART %>%
unnest_tokens(Palabra, text, token='ngrams', n = 2)
DATA_ART %>%
unnest_tokens(Palabra, text, token='ngrams', n = 2) %>%
separate(Palabra, c('word1', 'word2'), sep=' ') %>%
filter(!word1%in%stopwords('es')) %>%
filter(!word2%in%stopwords('es')) %>%
filter(!word1%in%silly_words) %>%
filter(!word2%in%silly_words) %>%
filter(str_detect(word1, "^[a-zA-z]|^#|^@")) %>%
filter(str_detect(word2, "^[a-zA-z]|^#|^@"))
DATA_ART %>%
unnest_tokens(Palabra, text, token='ngrams', n = 2) %>%
separate(Palabra, c('word1', 'word2'), sep=' ') %>%
filter(!word1%in%stopwords('es')) %>%
filter(!word2%in%stopwords('es')) %>%
filter(!word1%in%silly_words) %>%
filter(!word2%in%silly_words) %>%
filter(str_detect(word1, "^[a-zA-z]|^#|^@")) %>%
filter(str_detect(word2, "^[a-zA-z]|^#|^@")) %>%
count(word1, word2, sort=TRUE)
DATA_ART %>%
unnest_tokens(Palabra, text, token='ngrams', n = 2) %>%
separate(Palabra, c('word1', 'word2'), sep=' ') %>%
filter(!word1%in%stopwords('es')) %>%
filter(!word2%in%stopwords('es')) %>%
filter(!word1%in%silly_words) %>%
filter(!word2%in%silly_words) %>%
filter(str_detect(word1, "^[a-zA-z]|^#|^@")) %>%
filter(str_detect(word2, "^[a-zA-z]|^#|^@")) %>%
count(word1, word2, sort=TRUE) %>%
unite(Palabra, word1, word2, sep=' ') %>%
ungroup() %>%
arrange(desc(n)) %>%
mutate(word=Palabra,
freq=n) %>%
select(word, freq)
DATA_ART %>%
unnest_tokens(Palabra, text, token='ngrams', n = 3) %>%
separate(Palabra, c('word1', 'word2'), sep=' ') %>%
filter(!word1%in%stopwords('es')) %>%
filter(!word2%in%stopwords('es')) %>%
filter(!word1%in%silly_words) %>%
filter(!word2%in%silly_words) %>%
filter(str_detect(word1, "^[a-zA-z]|^#|^@")) %>%
filter(str_detect(word2, "^[a-zA-z]|^#|^@")) %>%
count(word1, word2, sort=TRUE) %>%
unite(Palabra, word1, word2, sep=' ') %>%
ungroup() %>%
arrange(desc(n)) %>%
mutate(word=Palabra,
freq=n) %>%
select(word, freq)
DATA_ART %>%
unnest_tokens(Palabra, text, token='ngrams', n = 2) %>%
separate(Palabra, c('word1', 'word2'), sep=' ') %>%
filter(!word1%in%stopwords('es')) %>%
filter(!word2%in%stopwords('es')) %>%
filter(!word1%in%silly_words) %>%
filter(!word2%in%silly_words) %>%
filter(str_detect(word1, "^[a-zA-z]|^#|^@")) %>%
filter(str_detect(word2, "^[a-zA-z]|^#|^@")) %>%
count(word1, word2, sort=TRUE) %>%
unite(Palabra, word1, word2, sep=' ') %>%
ungroup() %>%
arrange(desc(n)) %>%
mutate(word=Palabra,
freq=n) %>%
select(word, freq)
DATA_ART %>%
unnest_tokens(Palabra, text, token='ngrams', n = 2) %>%
separate(Palabra, c('word1', 'word2'), sep=' ') %>%
filter(!word1%in%stopwords('es')) %>%
filter(!word2%in%stopwords('es')) %>%
filter(!word1%in%silly_words) %>%
filter(!word2%in%silly_words) %>%
filter(str_detect(word1, "^[a-zA-z]|^#|^@")) %>%
filter(str_detect(word2, "^[a-zA-z]|^#|^@")) %>%
count(word1, word2, sort=TRUE) %>%
unite(Palabra, word1, word2, sep=' ') %>%
ungroup() %>%
arrange(desc(n)) %>%
mutate(word=Palabra,
freq=n) %>%
select(word, freq)
knitr::opts_chunk$set(echo = TRUE)
## install remotes packages
install.packages(c("syuzhet","SnowballC","ggwordcloud"))
install.packages(c("syuzhet", "SnowballC", "ggwordcloud"))
library(tidyverse)
library(tidytext)
library(tm)
library(proustr)
library(syuzhet)
library(SnowballC)
library(ggwordcloud)
sdal <- read.csv('https://hernanescu.github.io/data/SDAL_2.csv', encoding = 'UTF-8') %>%
rename('word'=palabra)
View(sdal)
sdal %>% head()
table(sdal$tipo)
DATA_ART %>%
unnest_tokens(Palabra, text) %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^#|^@")) %>%
arrange(desc(n))
DATA_ART_TOK <- DATA_ART %>%
unnest_tokens(Palabra, text) %>%
count(Palabra, sort = TRUE) %>%
filter(!Palabra%in%stopwords('es')) %>%
filter(!Palabra%in%silly_words) %>%
filter(str_detect(Palabra,"^[a-zA-z]|^#|^@")) %>%
arrange(desc(n))
View(DATA_ART)
DATA_ART_TOK <- DATA_ART_TOK %>%
rename('word'=Palabra)
DATA_ART_TOK_SDAL <- left_join(DATA_ART_TOK, sdal)
DATA_ART_TOK_SDAL %>% head()
DATA_ART_TOK_SDAL <- DATA_ART_TOK_SDAL %>%
filter(!is.na(media_agrado)) %>%
arrange(desc(media_agrado))
View(DATA_ART_TOK_SDAL)
token_neg <- DATA_ART_TOK_SDAL %>%
arrange(media_agrado) %>%
.[1:50,]
token_pos <-DATA_ART_TOK_SDAL %>%
arrange(desc(media_agrado)) %>%
.[1:50,]
View(token_neg)
View(token_pos)
token_neg %>%
mutate(n=case_when(word=='pierde'~524,
TRUE~as.numeric(n)))
mutate(n=case_when(word=='pierdas'~524,
TRUE~as.numeric(n)))
token_neg %>%
mutate(n=case_when(word=='guerra'~524,
TRUE~as.numeric(n)))
View(token_neg)
View(token_neg)
View(token_neg)
token_pos <-DATA_ART_TOK_SDAL %>%
arrange(desc(media_agrado)) %>%
.[1:50,]
